{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee00e13c",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preprocessing Lab Work\n",
    "\n",
    "This notebook walks through the steps of preprocessing a dataset to prepare it for machine learning models. \n",
    "The dataset consists of information on countries, age, salary, and whether a purchase was made.\n",
    "\n",
    "### Objectives:\n",
    "1. Handle missing data.\n",
    "2. Encode categorical variables.\n",
    "3. Avoid the dummy variable trap.\n",
    "4. Prepare the data for machine learning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3088e",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "Import the necessary libraries for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37237c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cbe73",
   "metadata": {},
   "source": [
    "## Step 2: Load the Dataset\n",
    "Load the dataset into a pandas DataFrame for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ef1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('Data.csv')  # Ensure 'Data.csv' is in the same directory\n",
    "X = dataset.iloc[:, :-1].values  # Independent variables\n",
    "y = dataset.iloc[:, 3].values  # Dependent variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15142e68",
   "metadata": {},
   "source": [
    "## Step 3: Handle Missing Data\n",
    "Replace missing values in numerical columns with their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing data using SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X[:, 1:3])  # Fit to Age and Salary columns\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])  # Transform missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a6969",
   "metadata": {},
   "source": [
    "## Step 4: Encode Categorical Data\n",
    "Convert categorical data (e.g., Country) to numerical values using label encoding and one-hot encoding. Avoid the dummy variable trap by dropping the first column of the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Label encode the 'Country' column\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "\n",
    "# One-hot encode and drop the first dummy variable to avoid the dummy variable trap\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(drop='first'), [0])], remainder='passthrough'\n",
    ")\n",
    "X = column_transformer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c0630",
   "metadata": {},
   "source": [
    "## Step 5: Encode Dependent Variable\n",
    "Convert the dependent variable 'Purchased' into binary numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da374c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode the dependent variable\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634a79b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have successfully preprocessed the dataset, handling missing values, encoding categorical variables, and avoiding the dummy variable trap. The data is now ready for use in machine learning models."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}